{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trial Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import seaborn as sns\n",
    "\n",
    "from numpy import array\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing import sequence\n",
    "from keras.layers.core import Activation, Dropout, Dense\n",
    "from keras.layers import Flatten, LSTM\n",
    "from keras.layers import GlobalMaxPooling1D\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "from keras import optimizers\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Embedding, Conv1D, MaxPooling1D, GlobalMaxPooling1D \n",
    "from keras.layers.embeddings import Embedding\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.layers import Input\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.layers import Embedding\n",
    "\n",
    "from tqdm import tqdm\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer \n",
    "import os, re, csv, math, codecs\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows: 239850\n"
     ]
    }
   ],
   "source": [
    "feature_df = pd.read_csv('./cleaned_csv/feature_df.csv',low_memory=False)\n",
    "print('rows:',len(feature_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>original_word_count</th>\n",
       "      <th>original_average_word_length</th>\n",
       "      <th>stopword_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Neutral</td>\n",
       "      <td>big group make reservation week advance</td>\n",
       "      <td>0.120370</td>\n",
       "      <td>0.055914</td>\n",
       "      <td>0.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Neutral</td>\n",
       "      <td>wait 20 minute drink another 30 breakfast not ...</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.081413</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Neutral</td>\n",
       "      <td>veggie cheese steak russian coleslaw like vega...</td>\n",
       "      <td>0.092593</td>\n",
       "      <td>0.086022</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Neutral</td>\n",
       "      <td>essential climb rope harness climb shoe beer</td>\n",
       "      <td>0.064815</td>\n",
       "      <td>0.107527</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Neutral</td>\n",
       "      <td>cleanest asian grocery store spotless organize...</td>\n",
       "      <td>0.175926</td>\n",
       "      <td>0.098310</td>\n",
       "      <td>0.190476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239845</th>\n",
       "      <td>Poor</td>\n",
       "      <td>lazy as bitch</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.060932</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239846</th>\n",
       "      <td>Poor</td>\n",
       "      <td>fastest wing ever hit table4 minute flat</td>\n",
       "      <td>0.064815</td>\n",
       "      <td>0.090800</td>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239847</th>\n",
       "      <td>Poor</td>\n",
       "      <td>worst service warm beer girl never clue 18 u o...</td>\n",
       "      <td>0.287037</td>\n",
       "      <td>0.059954</td>\n",
       "      <td>0.363636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239848</th>\n",
       "      <td>Poor</td>\n",
       "      <td>delivery faster expect</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.086022</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239849</th>\n",
       "      <td>Poor</td>\n",
       "      <td>pizza wasnt even cook way dough still raw</td>\n",
       "      <td>0.101852</td>\n",
       "      <td>0.066170</td>\n",
       "      <td>0.384615</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>239850 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentiment                                       cleaned_text  \\\n",
       "0        Neutral            big group make reservation week advance   \n",
       "1        Neutral  wait 20 minute drink another 30 breakfast not ...   \n",
       "2        Neutral  veggie cheese steak russian coleslaw like vega...   \n",
       "3        Neutral       essential climb rope harness climb shoe beer   \n",
       "4        Neutral  cleanest asian grocery store spotless organize...   \n",
       "...          ...                                                ...   \n",
       "239845      Poor                                      lazy as bitch   \n",
       "239846      Poor           fastest wing ever hit table4 minute flat   \n",
       "239847      Poor  worst service warm beer girl never clue 18 u o...   \n",
       "239848      Poor                             delivery faster expect   \n",
       "239849      Poor          pizza wasnt even cook way dough still raw   \n",
       "\n",
       "        original_word_count  original_average_word_length  stopword_ratio  \n",
       "0                  0.120370                      0.055914        0.533333  \n",
       "1                  0.111111                      0.081413        0.285714  \n",
       "2                  0.092593                      0.086022        0.333333  \n",
       "3                  0.064815                      0.107527        0.111111  \n",
       "4                  0.175926                      0.098310        0.190476  \n",
       "...                     ...                           ...             ...  \n",
       "239845             0.037037                      0.060932        0.333333  \n",
       "239846             0.064815                      0.090800        0.222222  \n",
       "239847             0.287037                      0.059954        0.363636  \n",
       "239848             0.037037                      0.086022        0.500000  \n",
       "239849             0.101852                      0.066170        0.384615  \n",
       "\n",
       "[239850 rows x 5 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(239598, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>original_word_count</th>\n",
       "      <th>original_average_word_length</th>\n",
       "      <th>stopword_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Neutral</td>\n",
       "      <td>big group make reservation week advance</td>\n",
       "      <td>0.120370</td>\n",
       "      <td>0.055914</td>\n",
       "      <td>0.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Neutral</td>\n",
       "      <td>wait 20 minute drink another 30 breakfast not ...</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.081413</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Neutral</td>\n",
       "      <td>veggie cheese steak russian coleslaw like vega...</td>\n",
       "      <td>0.092593</td>\n",
       "      <td>0.086022</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Neutral</td>\n",
       "      <td>essential climb rope harness climb shoe beer</td>\n",
       "      <td>0.064815</td>\n",
       "      <td>0.107527</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Neutral</td>\n",
       "      <td>cleanest asian grocery store spotless organize...</td>\n",
       "      <td>0.175926</td>\n",
       "      <td>0.098310</td>\n",
       "      <td>0.190476</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment                                       cleaned_text  \\\n",
       "0   Neutral            big group make reservation week advance   \n",
       "1   Neutral  wait 20 minute drink another 30 breakfast not ...   \n",
       "2   Neutral  veggie cheese steak russian coleslaw like vega...   \n",
       "3   Neutral       essential climb rope harness climb shoe beer   \n",
       "4   Neutral  cleanest asian grocery store spotless organize...   \n",
       "\n",
       "   original_word_count  original_average_word_length  stopword_ratio  \n",
       "0             0.120370                      0.055914        0.533333  \n",
       "1             0.111111                      0.081413        0.285714  \n",
       "2             0.092593                      0.086022        0.333333  \n",
       "3             0.064815                      0.107527        0.111111  \n",
       "4             0.175926                      0.098310        0.190476  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(feature_df.shape)\n",
    "\n",
    "feature_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature_df = feature_df.sample(n=10000) # we use all of the samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df = feature_df[['sentiment','cleaned_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies = pd.get_dummies(feature_df['sentiment']) #create dummies for labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "atom_col = [c for c in dummies.columns if '*' not in c]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-36-e513d7692cb6>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  feature_df[col] = dummies[[c for c in dummies.columns if col in c]].sum(axis=1)\n"
     ]
    }
   ],
   "source": [
    "for col in atom_col:\n",
    "    feature_df[col] = dummies[[c for c in dummies.columns if col in c]].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df = feature_df.drop(columns = [\"sentiment\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>Good</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Poor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>big group make reservation week advance</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wait 20 minute drink another 30 breakfast not ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>veggie cheese steak russian coleslaw like vega...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>essential climb rope harness climb shoe beer</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cleanest asian grocery store spotless organize...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239845</th>\n",
       "      <td>lazy as bitch</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239846</th>\n",
       "      <td>fastest wing ever hit table4 minute flat</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239847</th>\n",
       "      <td>worst service warm beer girl never clue 18 u o...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239848</th>\n",
       "      <td>delivery faster expect</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239849</th>\n",
       "      <td>pizza wasnt even cook way dough still raw</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>239598 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             cleaned_text  Good  Neutral  Poor\n",
       "0                 big group make reservation week advance     0        1     0\n",
       "1       wait 20 minute drink another 30 breakfast not ...     0        1     0\n",
       "2       veggie cheese steak russian coleslaw like vega...     0        1     0\n",
       "3            essential climb rope harness climb shoe beer     0        1     0\n",
       "4       cleanest asian grocery store spotless organize...     0        1     0\n",
       "...                                                   ...   ...      ...   ...\n",
       "239845                                      lazy as bitch     0        0     1\n",
       "239846           fastest wing ever hit table4 minute flat     0        0     1\n",
       "239847  worst service warm beer girl never clue 18 u o...     0        0     1\n",
       "239848                             delivery faster expect     0        0     1\n",
       "239849          pizza wasnt even cook way dough still raw     0        0     1\n",
       "\n",
       "[239598 rows x 4 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_df #this is the feature_df with three dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Poor</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Good</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Poor  Neutral  Good\n",
       "0     0        1     0\n",
       "1     0        1     0\n",
       "2     0        1     0\n",
       "3     0        1     0\n",
       "4     0        1     0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_df_comments_labels = feature_df[[\"Poor\", \"Neutral\", \"Good\"]]\n",
    "feature_df_comments_labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-lable Text Classification Model with Multiple Output Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(sen):\n",
    "    # Remove punctuations and numbers\n",
    "    sentence = re.sub('[^a-zA-Z]', ' ', sen)\n",
    "\n",
    "    # Single character removal\n",
    "    sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)\n",
    "\n",
    "    # Removing multiple spaces\n",
    "    sentence = re.sub(r'\\s+', ' ', sentence)\n",
    "\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "sentences = list(feature_df[\"cleaned_text\"])\n",
    "for sen in sentences:\n",
    "    X.append(preprocess_text(sen))\n",
    "\n",
    "y = feature_df[[\"Poor\",\"Neutral\",\"Good\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=123) #train_test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First output\n",
    "y1_train = y_train[[\"Poor\"]].values\n",
    "y1_test =  y_test[[\"Poor\"]].values\n",
    "\n",
    "# Second output\n",
    "y2_train = y_train[[\"Neutral\"]].values\n",
    "y2_test =  y_test[[\"Neutral\"]].values\n",
    "\n",
    "# Third output\n",
    "y3_train = y_train[[\"Good\"]].values\n",
    "y3_test =  y_test[[\"Good\"]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert textual inputs to embedded vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "maxlen = 200\n",
    "\n",
    "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_file = open('wiki-news-300d-1M.vec', encoding=\"utf8\") #pre-trained\n",
    "\n",
    "#We need to download the wiki-news-300d-1M file befoe we run this notebook\n",
    "\n",
    "for line in fast_file:\n",
    "    records = line.split()\n",
    "    word = records[0]\n",
    "    vector_dimensions = asarray(records[1:], dtype='float32')\n",
    "    embeddings_dictionary[word] = vector_dimensions\n",
    "fast_file.close()\n",
    "\n",
    "embedding_matrix = zeros((vocab_size, 300))\n",
    "for word, index in tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings_dictionary.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[index] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_1 = Input(shape=(maxlen,))\n",
    "embedding_layer = Embedding(vocab_size, 300, weights=[embedding_matrix], trainable=False)(input_1)\n",
    "LSTM_Layer1 = LSTM(128)(embedding_layer)\n",
    "\n",
    "output1 = Dense(1, activation='sigmoid')(LSTM_Layer1)\n",
    "output2 = Dense(1, activation='sigmoid')(LSTM_Layer1)\n",
    "output3 = Dense(1, activation='sigmoid')(LSTM_Layer1)\n",
    "\n",
    "\n",
    "model = Model(inputs=input_1, outputs=[output1, output2, output3])\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 200)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 200, 300)     13753200    input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 128)          219648      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            129         lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            129         lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1)            129         lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 13,973,235\n",
      "Trainable params: 220,035\n",
      "Non-trainable params: 13,753,200\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(model, to_file='model_plot4b.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "19/19 [==============================] - 811s 43s/step - loss: 2.0177 - dense_1_loss: 0.6705 - dense_2_loss: 0.6745 - dense_3_loss: 0.6728 - dense_1_acc: 0.6648 - dense_2_acc: 0.6684 - dense_3_acc: 0.6669 - val_loss: 1.9872 - val_dense_1_loss: 0.6654 - val_dense_2_loss: 0.6593 - val_dense_3_loss: 0.6625 - val_dense_1_acc: 0.6678 - val_dense_2_acc: 0.6645 - val_dense_3_acc: 0.6677\n",
      "Epoch 2/5\n",
      "19/19 [==============================] - 801s 42s/step - loss: 1.9563 - dense_1_loss: 0.6548 - dense_2_loss: 0.6485 - dense_3_loss: 0.6530 - dense_1_acc: 0.6648 - dense_2_acc: 0.6684 - dense_3_acc: 0.6669 - val_loss: 1.9117 - val_dense_1_loss: 0.6369 - val_dense_2_loss: 0.6380 - val_dense_3_loss: 0.6368 - val_dense_1_acc: 0.6678 - val_dense_2_acc: 0.6645 - val_dense_3_acc: 0.6677\n",
      "Epoch 3/5\n",
      "19/19 [==============================] - 875s 46s/step - loss: 1.9122 - dense_1_loss: 0.6384 - dense_2_loss: 0.6366 - dense_3_loss: 0.6371 - dense_1_acc: 0.6648 - dense_2_acc: 0.6684 - dense_3_acc: 0.6669 - val_loss: 1.9106 - val_dense_1_loss: 0.6361 - val_dense_2_loss: 0.6383 - val_dense_3_loss: 0.6362 - val_dense_1_acc: 0.6678 - val_dense_2_acc: 0.6645 - val_dense_3_acc: 0.6677\n",
      "Epoch 4/5\n",
      "19/19 [==============================] - 763s 40s/step - loss: 1.9101 - dense_1_loss: 0.6380 - dense_2_loss: 0.6356 - dense_3_loss: 0.6366 - dense_1_acc: 0.6648 - dense_2_acc: 0.6684 - dense_3_acc: 0.6669 - val_loss: 1.9098 - val_dense_1_loss: 0.6357 - val_dense_2_loss: 0.6382 - val_dense_3_loss: 0.6359 - val_dense_1_acc: 0.6678 - val_dense_2_acc: 0.6645 - val_dense_3_acc: 0.6677\n",
      "Epoch 5/5\n",
      "19/19 [==============================] - 692s 36s/step - loss: 1.9096 - dense_1_loss: 0.6379 - dense_2_loss: 0.6353 - dense_3_loss: 0.6364 - dense_1_acc: 0.6648 - dense_2_acc: 0.6684 - dense_3_acc: 0.6669 - val_loss: 1.9096 - val_dense_1_loss: 0.6358 - val_dense_2_loss: 0.6380 - val_dense_3_loss: 0.6358 - val_dense_1_acc: 0.6678 - val_dense_2_acc: 0.6645 - val_dense_3_acc: 0.6677\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=X_train, y=[y1_train, y2_train, y3_train], batch_size=8192, epochs=5, verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1498/1498 [==============================] - 184s 123ms/step - loss: 1.9096 - dense_1_loss: 0.6341 - dense_2_loss: 0.6369 - dense_3_loss: 0.6387 - dense_1_acc: 0.6703 - dense_2_acc: 0.6662 - dense_3_acc: 0.6635\n",
      "Test Score: 1.9096430540084839\n",
      "Test Accuracy: 0.6341055035591125\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x=X_test, y=[y1_test, y2_test, y3_test], verbose=1)\n",
    "\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1]) # accuracy on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the final test accuracy is 0.63"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
